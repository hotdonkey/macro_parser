{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LME parsing is DONE!\n",
      "KITCO parsing is DONE!\n",
      "Empty data set in CentroBank_currency. Should check the source.\n",
      "Empty data set in CentroBank_metalls . Should check the source.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "#This parser uses API's data mostly. Tried bs at firs but it was unnesesary.\n",
    "\n",
    "\n",
    "def lme_db_addition():\n",
    "\n",
    "    def get_day_info():\n",
    "\n",
    "        # URL API for every metall, place into the var\n",
    "        url_aluminium = 'https://www.lme.com/api/trading-data/day-delayed?datasourceId=1a0ef0b6-3ee6-4e44-a415-7a313d5bd771'\n",
    "        url_copper = 'https://www.lme.com/api/trading-data/day-delayed?datasourceId=762a3883-b0e1-4c18-b34b-fe97a1f2d3a5'\n",
    "        url_lead = 'https://www.lme.com/api/trading-data/day-delayed?datasourceId=bc443de6-0bdd-4464-8845-9504f528b0c6'\n",
    "        url_nikel = 'https://www.lme.com/api/trading-data/day-delayed?datasourceId=acadf037-c13f-42f2-b42a-cac9a8179940'\n",
    "        url_zink = 'https://www.lme.com/api/trading-data/day-delayed?datasourceId=c389e2b0-c4a3-46a0-96ca-69cacbe90ee4'\n",
    "\n",
    "        # List for iterations\n",
    "        req_list = {'aluminium': url_aluminium, 'copper': url_copper,\n",
    "                    'lead': url_lead, 'nikel': url_nikel, 'zink': url_zink}\n",
    "\n",
    "        # Empty dict for final row-stage\n",
    "        day_dict = {'date': [], 'aluminium': [], 'copper': [],\n",
    "                    'lead': [], 'nikel': [], 'zink': [], }\n",
    "\n",
    "        # Getting json from api's requests and taking the info (in our case OFFER price for a date)\n",
    "        for metal, url in req_list.items():\n",
    "            req = requests.get(url).json()\n",
    "            metal_dict = req['Rows'][0]\n",
    "            day_dict[metal] = float(metal_dict['Values'][1])\n",
    "            day_dict['date'] = metal_dict['BusinessDateTime']\n",
    "\n",
    "        # Transform dict from previous stage into the row\n",
    "        dict_ = dict(day_dict)  # Maybe can simplify this\n",
    "        day_row = pd.DataFrame([dict_])\n",
    "        day_row.date = pd.to_datetime(day_row.date)\n",
    "\n",
    "        return day_row  # This is our row for implimentation into the main base\n",
    "\n",
    "    # Opening main base, add a row, check for dupp, saving and closing\n",
    "    lme_db = pd.read_excel(\n",
    "        '/Users/hotdonkey/Documents/GitHub/data_science_learning/code/LME/parser_beta/data/LME_db.xlsx', index_col=0)\n",
    "    day_row = get_day_info()\n",
    "    lme_db = pd.concat([lme_db, day_row], axis=0, ignore_index=True)\n",
    "    lme_db.drop_duplicates(inplace=True)\n",
    "\n",
    "    with pd.ExcelWriter(\n",
    "        \"/Users/hotdonkey/Documents/GitHub/data_science_learning/code/LME/parser_beta/data/LME_db.xlsx\",\n",
    "        date_format=\"YYYY-MM-DD\",\n",
    "            datetime_format=\"YYYY-MM-DD\") as writer:\n",
    "        lme_db.to_excel(writer, sheet_name='LME_non_ferrous')\n",
    "\n",
    "    print('LME parsing is DONE!')\n",
    "\n",
    "    return lme_db\n",
    "\n",
    "\n",
    "def kitco_db():\n",
    "    #In KITCO parsing we're taking slightly different aproach, we need to reupload \n",
    "    #the table into the file because sometimes KITCO changing data backdating\n",
    "    url = 'https://www.kitco.com/gold.londonfix.html'\n",
    "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "    kitco_response = pd.read_html(response.text)\n",
    "    kitco_df = pd.read_excel(\n",
    "        '/Users/hotdonkey/Documents/GitHub/data_science_learning/code/LME/parser_beta/data/kitko_db.xlsx', index_col=0)\n",
    "\n",
    "    #Get the raw table and drop unnesesary rows\n",
    "    kitco_day = kitco_response[1]\n",
    "    kitco_day.drop([1, 4, 6], axis=1, inplace=True)\n",
    "    kitco_day.columns = kitco_day.iloc[0]\n",
    "    kitco_day.drop([0, 1, 2], axis=0, inplace=True)\n",
    "    \n",
    "    #Change tyoe of data within table\n",
    "    kitco_day['Date'] = pd.to_datetime(kitco_day['Date'])\n",
    "    kitco_day = kitco_day.replace({'-': np.nan})\n",
    "    kitco_day = kitco_day.sort_values(by=['Date'])\n",
    "    kitco_day = kitco_day.reset_index(drop=True)\n",
    "    kitco_day[['Gold', 'Silver', 'Platinum', 'Palladium']] = kitco_day[[\n",
    "        'Gold', 'Silver', 'Platinum', 'Palladium']].apply(pd.to_numeric)\n",
    "\n",
    "    kitco_day.drop_duplicates(inplace=True)\n",
    "\n",
    "    #And rewrite old table\n",
    "    kitco_day.to_excel(\n",
    "        '/Users/hotdonkey/Documents/GitHub/data_science_learning/code/LME/parser_beta/data/kitko_db.xlsx', sheet_name='kitco_metall')\n",
    "\n",
    "    print('KITCO parsing is DONE!')\n",
    "\n",
    "    return kitco_day\n",
    "\n",
    "\n",
    "def cb_curr():\n",
    "    day = date.today()\n",
    "    today = day.strftime('%d/%m/%Y')\n",
    "\n",
    "    dict_of_currencies = {\n",
    "        'R01235': 'USD',\n",
    "        'R01239': 'EUR',\n",
    "        'R01010': 'Australian_Dollar',\n",
    "        'R01375': 'China_Yuan',\n",
    "        'R01035': 'British_Pound',\n",
    "        'R01335': 'Kazakhstan_Tenge',\n",
    "        'R01815': 'Japanese_Yen',\n",
    "        'R01775': 'Swiss_Franc'\n",
    "    }\n",
    "\n",
    "    list_of_currencies = [x for x in dict_of_currencies.keys()]\n",
    "\n",
    "    URL_list = []\n",
    "    for currency in list_of_currencies:\n",
    "        URL = f'http://www.cbr.ru/scripts/XML_dynamic.asp?date_req1={today}&date_req2={today}&VAL_NM_RQ={currency}'\n",
    "        URL_list.append(URL)\n",
    "\n",
    "    currency_df = pd.read_excel(\n",
    "        '/Users/hotdonkey/Documents/GitHub/data_science_learning/code/LME/parser_beta/data/cb_curr.xlsx', index_col=0)\n",
    "\n",
    "    #This problem occurs in the beginning of the year so I was forced to catch a ValueError\n",
    "    try:\n",
    "        for url_element in URL_list:\n",
    "            response_df = pd.read_xml(url_element)\n",
    "            response_df['Date'] = pd.to_datetime(\n",
    "                response_df['Date'], dayfirst=True)\n",
    "            response_df['Value'] = response_df['Value'].apply(\n",
    "                lambda x: x.replace(',', '.'))\n",
    "            response_df['Value'] = response_df['Value'].apply(pd.to_numeric)\n",
    "            response_df = response_df.replace(dict_of_currencies)\n",
    "            currency_df = pd.concat(\n",
    "                [currency_df, response_df], axis=0, ignore_index=True)\n",
    "            currency_df.drop_duplicates(inplace=True)\n",
    "        print('CentroBank_currency parsing is DONE!')\n",
    "\n",
    "    except ValueError:\n",
    "        print('Empty data set in CentroBank_currency. Should check the source.')\n",
    "\n",
    "    with pd.ExcelWriter(\n",
    "            \"/Users/hotdonkey/Documents/GitHub/data_science_learning/code/LME/parser_beta/data/cb_curr.xlsx\") as writer:\n",
    "        currency_df.to_excel(writer, sheet_name='curr')\n",
    "\n",
    "    return currency_df\n",
    "\n",
    "\n",
    "def cb_metall():\n",
    "    day = date.today()\n",
    "    today = day.strftime('%d/%m/%Y')\n",
    "\n",
    "    metall_dict = {\n",
    "        1: 'gold',\n",
    "        2: 'silver',\n",
    "        3: 'platinum',\n",
    "        4: 'palladium'\n",
    "    }\n",
    "\n",
    "    URL = f'http://www.cbr.ru/scripts/xml_metall.asp?date_req1={today}&date_req2={today}'\n",
    "\n",
    "    metall_df = pd.read_excel(\n",
    "        '/Users/hotdonkey/Documents/GitHub/data_science_learning/code/LME/parser_beta/data/cb_metall.xlsx', index_col=0)\n",
    "\n",
    "    #This problem occurs in the beginning of the year so I was forced to catch a ValueError\n",
    "    try:\n",
    "        response_df = pd.read_xml(URL)\n",
    "        response_df.drop(columns='Buy', axis=1, inplace=True)\n",
    "        response_df['Date'] = pd.to_datetime(\n",
    "            response_df['Date'], dayfirst=True)\n",
    "        response_df['Sell'] = response_df['Sell'].apply(\n",
    "            lambda x: x.replace(',', '.')) #changing for future retyping to numeric\n",
    "        response_df['Sell'] = response_df['Sell'].apply(pd.to_numeric)\n",
    "        response_df = response_df.replace(metall_dict)\n",
    "\n",
    "        metall_df = pd.concat(\n",
    "            [metall_df, response_df],\n",
    "            axis=0,\n",
    "            ignore_index=True)\n",
    "\n",
    "        metall_df.drop_duplicates(inplace=True)\n",
    "\n",
    "        print('CentroBank_metalls parsing is DONE!')\n",
    "\n",
    "    except ValueError:\n",
    "        print('Empty data set in CentroBank_metalls . Should check the source.')\n",
    "\n",
    "    with pd.ExcelWriter(\n",
    "            '/Users/hotdonkey/Documents/GitHub/data_science_learning/code/LME/parser_beta/data/cb_metall.xlsx',\n",
    "            date_format='YYYY-MM-DD',\n",
    "            datetime_format='YYYY-MM-DD') as writer:\n",
    "        metall_df.to_excel(writer, sheet_name='cb_metall')\n",
    "\n",
    "    return metall_df\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lme_db_addition()\n",
    "    kitco_db()\n",
    "    cb_curr()\n",
    "    cb_metall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
